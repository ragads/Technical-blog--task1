{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "base_url = \"https://detailed.com/tech-blogs/?form=MG0AV3\"\n",
        "\n",
        "\n",
        "urls = [base_url] * 50\n",
        "\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "}\n",
        "\n",
        "def scrape_data(url, index):\n",
        "    try:\n",
        "        response = requests.get(url, headers=HEADERS)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "\n",
        "        td_elements = soup.find_all(\"td\", class_=\"blog-content\")\n",
        "\n",
        "\n",
        "        if index < len(td_elements):\n",
        "            h3_tag = td_elements[index].find(\"h3\")\n",
        "            title = h3_tag.text.strip() if h3_tag else \"N/A\"\n",
        "            a_tag = td_elements[index].find(\"a\", target=\"_blank\")\n",
        "            blog_url = a_tag[\"href\"] if a_tag else \"N/A\"\n",
        "            span_tag=td_elements[index].find(\"span\",class_=\"blog-description\")\n",
        "            description=span_tag.text.strip() if span_tag else \"N/A\"\n",
        "\n",
        "\n",
        "        else:\n",
        "            title = \"N/A\"\n",
        "            blog_url=\"N/A\",\n",
        "            description=\"N/A\",\n",
        "\n",
        "\n",
        "        return {\n",
        "            \"Title\": title,\n",
        "            \"blog_url\": blog_url,\n",
        "            \"description\":description,\n",
        "\n",
        "\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error scraping data from {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "news = []\n",
        "for i in range(len(urls)):\n",
        "    data = scrape_data(urls[i], i)\n",
        "    if data:\n",
        "        news.append(data)\n",
        "\n",
        "\n",
        "data_df = pd.DataFrame(news)\n",
        "csv_filename = \"technical_blog.csv\"\n",
        "data_df.to_csv(csv_filename, index=False)\n",
        "\n",
        "\n",
        "print(data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI2GoKmGnP4z",
        "outputId": "b276359f-be49-44e8-b4e9-e9858c951ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      Title                             blog_url  \\\n",
            "0                   Gizmodo                 https://gizmodo.com/   \n",
            "1                   9to5Mac                 https://9to5mac.com/   \n",
            "2                Mac Rumors           https://www.macrumors.com/   \n",
            "3                  Engadget            https://www.engadget.com/   \n",
            "4                      CNET           https://www.cnet.com/news/   \n",
            "5            Digital Trends       https://www.digitaltrends.com/   \n",
            "6               VentureBeat             https://venturebeat.com/   \n",
            "7                 The Verge            https://www.theverge.com/   \n",
            "8                  Mashable                https://mashable.com/   \n",
            "9             Apple Insider             http://appleinsider.com/   \n",
            "10             SiliconANGLE            https://siliconangle.com/   \n",
            "11                      BGR                       http://bgr.com   \n",
            "12               TechCrunch               https://techcrunch.com   \n",
            "13                    ZDNet               https://www.zdnet.com/   \n",
            "14        Android Authority    https://www.androidauthority.com/   \n",
            "15          Android Central      https://www.androidcentral.com/   \n",
            "16                  Tech.eu                      https://tech.eu   \n",
            "17                    Wired                https://www.wired.com   \n",
            "18             Ars Technica             https://arstechnica.com/   \n",
            "19                SlashGear           https://www.slashgear.com/   \n",
            "20                Techdirt.            https://www.techdirt.com/   \n",
            "21             The Next Web              https://thenextweb.com/   \n",
            "22                 Macworld             https://www.macworld.com   \n",
            "23                 TechSpot             https://www.techspot.com   \n",
            "24                 GeekWire            https://www.geekwire.com/   \n",
            "25             TechRepublic         https://www.techrepublic.com   \n",
            "26           Computer World       https://www.computerworld.com/   \n",
            "27              How-To Geek           https://www.howtogeek.com/   \n",
            "28               KnowTechie              https://knowtechie.com/   \n",
            "29             Tech in Asia           https://www.techinasia.com   \n",
            "30         Information Week         https://informationweek.com/   \n",
            "31               HackerNoon              https://hackernoon.com/   \n",
            "32             TorrentFreak             https://torrentfreak.com   \n",
            "33                ReadWrite               https://readwrite.com/   \n",
            "34           TrustedReviews       http://www.trustedreviews.com/   \n",
            "35                   Recode           https://www.vox.com/recode   \n",
            "36              Komando.com             https://www.komando.com/   \n",
            "37             Extreme Tech           http://www.extremetech.com   \n",
            "38  Technology Personalized                  https://techpp.com/   \n",
            "39              Stratechery             https://stratechery.com/   \n",
            "40            TechNewsWorld       https://www.technewsworld.com/   \n",
            "41                      e27                      https://e27.co/   \n",
            "42              TalkAndroid         https://www.talkandroid.com/   \n",
            "43               GroovyPost          https://www.groovypost.com/   \n",
            "44           Tech Commuters       https://www.techcommuters.com/   \n",
            "45       Tech Business News  https://www.techbusinessnews.com.au   \n",
            "46              Techthelead              http://techthelead.com/   \n",
            "47                   Gigaom             https://gigaom.com/blog/   \n",
            "48                 The Loop          http://www.loopinsight.com/   \n",
            "49               TechEngage              https://techengage.com/   \n",
            "\n",
            "                                          description  \n",
            "0   Originally launched as a part of Gawker Media ...  \n",
            "1   Founded by Seth Weintraub 13 years ago, 9to5Ma...  \n",
            "2   Founded and owned by Arnold Kim, MacRumors att...  \n",
            "3   An original home for technology news and revie...  \n",
            "4   CNET tracks all the latest consumer technology...  \n",
            "5   Digital Trends is a technology news, lifestyle...  \n",
            "6   Founded 14 years ago, VentureBeat is the leadi...  \n",
            "7   The Verge is an ambitious multimedia effort fo...  \n",
            "8   Mashable is a global, multi-platform media and...  \n",
            "9   Launched over 20 years ago as a news and rumor...  \n",
            "10  SiliconAngle is a modern digital media platfor...  \n",
            "11  BGR is an online destination for news and revi...  \n",
            "12  Founded by Michael Arrington and later sold to...  \n",
            "13  Founded almost 30 years ago, Zdnet is a busine...  \n",
            "14  With over 7 million followers on social sites,...  \n",
            "15  AndroidCentral is led by a team of experts and...  \n",
            "16  Tech.eu is the premier online publication dedi...  \n",
            "17  Wired.com focuses on how emerging technologies...  \n",
            "18  Founded by Ken Fisher over 20 years ago, Arste...  \n",
            "19  SlashGear covers everything from cutting-edge ...  \n",
            "20  Techdirt is an internet blog that reports on t...  \n",
            "21  TheNextWeb brings insights to the world of tec...  \n",
            "22  A website dedicated to products and software o...  \n",
            "23  Established over 20 years ago with over 6 mill...  \n",
            "24  Started almost 10 years ago, Geekwire is a tec...  \n",
            "25  TechRepublic helps IT decision-makers identify...  \n",
            "26  Computerworld focuses on empowering enterprise...  \n",
            "27  How-To Geek is an online technology magazine c...  \n",
            "28  KnowTechie is a blog for people who love tech ...  \n",
            "29  Tech in Asia is a media, events, and jobs plat...  \n",
            "30  InformationWeek is a dedicated website towards...  \n",
            "31  How hackers start their afternoons (40k+ contr...  \n",
            "32  Founded by Ernesto Van Der Sar, TorrentFreak i...  \n",
            "33  A next generation of tech media, ReadWrite agg...  \n",
            "34  TrustedReviews provides expert reviews of the ...  \n",
            "35  Owned by VOX media, Recode is a technology new...  \n",
            "36  Breaking tech news, digital-lifestyle tips and...  \n",
            "37  ExtremeTech is the internet's top destination ...  \n",
            "38  This is a Tech blog with a focus on personal a...  \n",
            "39  Stratechery provides analysis of the strategy ...  \n",
            "40  Technewsworld provides important technology ne...  \n",
            "41  E27 is a platform for news, community, events,...  \n",
            "42  TalkAndroid was founded in 2008, posting news ...  \n",
            "43  The blog covers all things technology includin...  \n",
            "44  Tech Commuters is a leading information techno...  \n",
            "45  Tech Business News is a reliable and popular o...  \n",
            "46  The latest tech news that actually matters, wi...  \n",
            "47  With over 6.5 million unique visitors each mon...  \n",
            "48  Filled with latest titbits of news about Apple...  \n",
            "49  TechEngage is the source of latest technology ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"technical_blog.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "plYGbYeMnQGg",
        "outputId": "7c71461c-c917-447e-a0e5-648f4d8040a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d40b11f9-d9de-4896-94da-85e1972ef2dd\", \"technical_blog.csv\", 10307)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u118sT9jowo2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}